## Table of Contents

  - [Table of Contents](#Table\of\Contents)
  - [Consists of the following elements](#Consists\of\the\following\elements)
  - [Memroy](#Memroy)
          - [Cache](#Cache)
          - [Ram](#Ram)
        - [RAM](#RAM)
      - [I/O Storage](#I/O\Storage)
  - [Instruction Cycle](#Instruction\Cycle)
  - [Processor Specific](#Processor\Specific)

## Table of Contents

  - [Consists of the following elements](#Consists\of\the\following\elements)
  - [Memroy](#Memroy)
          - [Cache](#Cache)
          - [Ram](#Ram)
        - [RAM](#RAM)
      - [I/O Storage](#I/O\Storage)
  - [Instruction Cycle](#Instruction\Cycle)
  - [Processor Specific](#Processor\Specific)

Today, most modern computers are built on what is known at the `Von Neumann Architecture`, which was developed back in **`1945`** by `Von Neumann` to enable the creation of "General-purporse computewrs."

## Consists of the following elements
- CPU
- Memory Unit
- Input/output fdevices
	- Mass storage unit
	- Keyboard
	- display

The **CPU** itself consists of three main components:
- Control Unit
- Arithmetic/Logic Unit (ALU)
- Register

Memory    CPU           I/O
>cache -> CU          Keyboard
> Ram  -> ALU < --- > Display
>        Registers    Storage

## Memroy
a computer memory is where the temporary data and instructions of currently running programs are located. A computer's memory is also known as Primary memory. It is the primary lcoation the CPU uses to retrieve and process data.

2 Types:
- Cache
- RAM


###### Cache
- Located within the CPU, hence fast.
- Runs at same clock speed as the CPU.
- Limited in size
- Expensive



###### Ram
- Much slower than the CPU cores, in addition to it being far from the CPU.
	- If a CPU had to wait for the RAM to retrieve each instruction it would be running at much lower clock speeds. This is the main benefit of cache memory. 
	- Enables the CPU to access the upcomning instructions and data quicker than from RAM

|   |   |
|---|---|
|`Level 1 Cache`|Usually in kilobytes, the fastest memory available, located in each CPU core. (Only registers are faster.)|
|`Level 2 Cache`|Usually in megabytes, extremely fast (but slower than L1), shared between all CPU cores.|
|`Level 3 Cache`|Usually in megabytes (larger than L2), faster than RAM but slower than L1/L2. (Not all CPUs use L3.)|

##### RAM
- Much larger than cache memory
- Ranges in sizes from GB to TB.
- Located far away from the CPU cores and is much slower the cache memory. Accessing data from RAM takes more instructions altogether.


In the past, with 32-bit addresses, memory addresses were limited from `0x00000000` to `0xffffffff`. This meant that the maximum possible RAM size was 232 bytes, which is only 4 gigabytes, at which point we run out of unique addresses. With 64-bit addresses, the range is now up to `0xffffffffffffffff`, with a theoretical maximum RAM size of 264 bytes, which is around 18.5 exabytes (18.5 million terabytes), so we shouldn't be running out of memory addresses anytime soon.

![](https://academy.hackthebox.com/storage/modules/85/memory_structure.jpg)

When a program is run, all of its data and instructions are moved from the storage unit to the RAM to be accessed when needed by the CPU. This happens because accessing them from the storage unit is much slower and will increase data processing times. When a program is closed, its data is removed or made available to re-use from the RAM.

As we can see, the RAM is split into four main `segments`:
- Stack: Last-in-first-out design and is fixed in size. DAta in it can only be accessed in a specific order by pushing an poping data.
	- `HEAP`: Has a hierarchal design and is therefore much larger and more versatile in storing data, as data can be stored and retrieved in any order. However, this makes the heap slowers than the stack.
	- `Data`: Two Parts, `data`, which is used to hold variables, and .bss which is used to hold unassigned variables. (buffer memory for later allocation
*Segmentation applies to the entire RAM. each appliucation is allocated its virtual mermory when it is run. This mean that each application would have its own `stack`, `heap`, `data`, and `text` segments.*


#### I/O Storage
(Input/output devices and such.)
- processor can acccess and control IO devices using `Bus Interfaces` which essentially acts as `highways` to transfer data and addresses using electrical charge for binary data.

- Each bus has a capacity of bits ( or electircal charges) it can carry simultaneously. This usually is a multiple of  `4` bits, ranging up to `128-bits`. But interfaces also usually used to access memrory and other components outside the CPU itself. 


- The storage unit is the slowest to access.
- Furthest away from the CPU.
- Slower in design to allow more data storage, as long as ther is more data to go through, they will be slower.

- Magnetic storage units (SSD's) utilize a similar design to RAM's using non-volatile circuitry that retains data even without electricity. This made storage units faster in soptrig and retrieving data.

|Component|Speed|Size|
|---|---|---|
|`Registers`|Fastest|Bytes|
|`L1 Cache`|Fastest, other than Registers|Kilobytes|
|`L2 Cache`|Very fast|Megabytes|
|`L3 Cache`|Fast, but slower than the above|Megabytes|
|`RAM`|Much slower than all of the above|Gigabytes-Terabytes|
|`Storage`|Slowest|Terabytes and more|

## Instruction Cycle

An `Instruction Cycle` is the cycle it takes the CPU to process a single machine instruction.

![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_instruction_cycle.jpg)

An instruction cycle consists of four stages: `Fetch`, `Decode`, `Execute`, and `Store`:

|**Instruction**|**Description**|
|---|---|
|`1. Fetch`|Takes the next instruction's address from the `Instruction Address Register` (IAR), which tells it where the next instruction is located.|
|`2. Decode`|Takes the instruction from the IAR, and decodes it from binary to see what is required to be executed.|
|`3. Execute`|Fetch instruction operands from register/memory, and process the instruction in the `ALU` or `CU`.|
|`4. Store`|Store the new value in the destination operand.|


Each Instruction Cycle takes multiple clock cycles to finish, depending on the CPU architecture and the complexity of the instruction. Once a single instruction cycle ends, the CU increments to the next instruction and runs the same cycle on it, and so on.

![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_clock_cycle_1.jpg)

For example, if we were to execute the assembly instruction `add rax, 1`, it would run through an instruction cycle:

1. Fetch the instruction from the `rip` register, `48 83 C0 01` (in binary).
2. Decode '`48 83 C0 01`' to know it needs to perform an `add` of `1` to the value at `rax`.
3. Get the current value at `rax` (by `CU`), add `1` to it (by the `ALU`).
4. Store the new value back to `rax`.

## Processor Specific

As previously mentioned, each processor understands a different set of instructions. For example, while an Intel processor based on the 64-bit x86 architecture may interpret the machine code `4883C001` as `add rax, 1`, an ARM processor translates the same machine code as the `biceq r8, r0, r8, asr #6` instruction. As we can see, the same machine code performs an entirely different instruction on each processor.




If we want to know whether our Linux system supports `x86_64` architecture, we can use the `lscpu` command:

```shell-session
gdxqpardo@htb[/htb]$ lscpu

Architecture:                    x86_64
```















