## Table of Contents

  - [Table of Contents](#Table\of\Contents)
    - [Memory](#Memory)
    - [Cache](#Cache)
      - [RAM](#RAM)
  - [IO/Storage](#IO/Storage)
  - [Speed](#Speed)
- [CPU Architecture](#cpu\architecture)
  - [Clock Speed & Clock Cycle](#Clock\Speed\&\Clock\Cycle)
  - [Instruction Cycle](#Instruction\Cycle)
  - [Processor Specific](#Processor\Specific)
    - [Instruction Set Architectures](#Instruction\Set\Architectures)
  - [Registers, Addresses and Data Types](#Registers,\Addresses\and\Data\Types)
          - [Registers](#Registers)
    - [CISC](#CISC)
    - [RISC](#RISC)
  - [CISC vs. RISC](#CISC\vs.\RISC)
          - [Glossary](#Glossary)

## Table of Contents

    - [Memory](#Memory)
    - [Cache](#Cache)
      - [RAM](#RAM)
  - [IO/Storage](#IO/Storage)
  - [Speed](#Speed)
- [CPU Architecture](#cpu\architecture)
  - [Clock Speed & Clock Cycle](#Clock\Speed\&\Clock\Cycle)
  - [Instruction Cycle](#Instruction\Cycle)
  - [Processor Specific](#Processor\Specific)
    - [Instruction Set Architectures](#Instruction\Set\Architectures)
  - [Registers, Addresses and Data Types](#Registers,\Addresses\and\Data\Types)
          - [Registers](#Registers)
    - [CISC](#CISC)
    - [RISC](#RISC)
  - [CISC vs. RISC](#CISC\vs.\RISC)
          - [Glossary](#Glossary)

Most computers are built on what is known as the `Von Neumann` Architecture.

This architecture executes machine code to perform specific algorithms. It mainly consists of the following elements:

- Central Processing Unit (CPU)
- Memory Unit
- Input/Output Devices
    - Mass Storage Unit
    - Keyboard
    - Display

Furthermore, the CPU itself consists of three main components:

- Control Unit (**CU**)
- Arithmetic/Logic Unit (**ALU**)
- Registers


![[von_neumann_arch.jpg]]



Furthermore, basic and advanced binary exploitation requires a proper understanding of computer architecture. With basic stack overflows, we only need to be aware of the general design. Once we start using ROP and Heap exploits, our understanding should be profound. Let us now take a deeper look into some essential components.


### Memory
A computer's memory is where the `temporary` data and instructions of currently running programs are located. A computer's memory is also known as the Primary Memory. It is the primary location the CPU uses to retrieve and process data. It does so billions of times a second, so the memory must be extremely fast in storing and retrieving data and instructions.

There are two main types of memory:

1. `Cache`
2. `Random Access Memory (RAM)`


### Cache
Cache memory is usually located within the CPU itself and hence is extremely fast compared to RAM, as it runs at the same clock speed as the CPU. However it is limited in size and very sophisticated, and expensive to manufacture due to it being so close to the CPU core.

Since RAM clock speed is usually much slower than the CPU cores, in addition to it being far from the CPU, if a CPU had to wait for the RAM to retrieve each instruction, it would effectively be running at much lower clock speeds. This is the main benefit of cache memory. It enables the CPU to access the upcoming instructions and data quicker than retrieving them from RAM.

There are usually three levels of cache memory, depending on their closeness to the CPU core:

|**Level**|**Description**|
|---|---|
|`Level 1 Cache`|Usually in kilobytes, the fastest memory available, located in each CPU core. (Only registers are faster.)|
|`Level 2 Cache`|Usually in megabytes, extremely fast (but slower than L1), shared between all CPU cores.|
|`Level 3 Cache`|Usually in megabytes (larger than L2), faster than RAM but slower than L1/L2. (Not all CPUs use L3.)|

#### RAM

RAM is much larger than cache memory, coming in sizes ranging from gigabytes up to terabytes. RAM is also located far away from the CPU cores and is much slower than cache memory. Accessing data from RAM addresses takes many more instructions.

For example, retrieving an instruction from the registers takes only one clock cycle, and retrieving it from the L1 cache takes a few cycles, while retrieving it from RAM takes around 200 cycles. When this is done billions of times a second, it makes a massive difference in the overall execution speed.

In the past, with 32-bit addresses, memory addresses were limited from `0x00000000` to `0xffffffff`. This meant that the maximum possible RAM size was 232 bytes, which is only 4 gigabytes, at which point we run out of unique addresses. With 64-bit addresses, the range is now up to `0xffffffffffffffff`, with a theoretical maximum RAM size of 264 bytes, which is around 18.5 exabytes (18.5 million terabytes), so we shouldn't be running out of memory addresses anytime soon.

RAM  is split into four main `segments`:

+------------+
\-    `STACK`    - <---- High Addresses
+------------+
       |
+------------+
\-     `Heap`     -
+------------+
\-    `Data`      -
+------------+
\-    `Text`     -
+------------+

| Segment | Description                                                                                                                                                                                      |
| ------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| `Stack` | Has a Last-in First-out (**LIFO**) design and is fixed in size. Data in it can only be accessed in a specific order by push-ing and pop-ing data.                                                |
| `Heap`  | Has a hierarchical design and is therefore much larger and more versatile in storing data, as data can be stored and retrieved in any order. However, this makes the heap slower than the Stack. |
| `Data`  | Has two parts: `Data`, which is used to hold variables, and `.bss`, which is used to hold unassigned variables (i.e., buffer memory for later allocation).                                       |
| `Text`  | Main assembly instructions are loaded into this segment to be fetched and executed by the CPU.                                                                                                   |

Although this segmentation applies to the entire RAM, `each application is allocated its Virtual Memory when it is run`. This means that each application would have its own `stack`, `heap`, `data`, and `text` segments.

## IO/Storage

Finally, we have the Input/Output devices, like the keyboard, the screen, or the long-term storage unit, also known as Secondary Memory. The processor can access and control IO devices using `Bus Interfaces`, which act as 'highways' to transfer data and addresses, using electrical charges for binary data.

Each Bus has a capacity of bits (or electrical charges) it can carry simultaneously. This usually is a multiple of 4-bits, ranging up to 128-bits. Bus interfaces are also usually used to access memory and other components outside the CPU itself. If we take a closer look at a CPU or a motherboard, we can see the bus interfaces all over them:


![bus](https://academy.hackthebox.com/storage/modules/85/cpu_bus.jpg)

Unlike primary memory that is volatile and stores temporary data and instructions as the programs are running, the storage unit stores permanent data, like the operating system files or entire applications and their data.

The storage unit is the slowest to access. First, because they are the farthest away from the CPU, accessing them through bus interfaces like SATA or USB takes much longer to store and retrieve the data. They are also slower in their design to allow more data storage. Î‘s long as there is more data to go through, they will be slower.

There has been a shift from classic magnetic storage units, like tapes or Hard Disk Drives (HDD), to Solid-State Drives (SSD) in recent years. This is because SSD's utilize a similar design to RAM's, using non-volatile circuitry that retains data even without electricity. This made storage units much faster in storing and retrieving data. Still, since they are far away from the CPU and connected through special interfaces, they are the slowest unit to access.


## Speed

As we can see from the above, the further away a component is from the CPU core, the slower it is. Also, the more data it can hold, the slower it is, as it simply has to go through more to fetch the data. The below table summarizes each component, its size, and its speed:

|Component|Speed|Size|
|---|---|---|
|`Registers`|Fastest|Bytes|
|`L1 Cache`|Fastest, other than Registers|Kilobytes|
|`L2 Cache`|Very fast|Megabytes|
|`L3 Cache`|Fast, but slower than the above|Megabytes|
|`RAM`|Much slower than all of the above|Gigabytes-Terabytes|
|`Storage`|Slowest|Terabytes and more|



# CPU Architecture

---

The Central Processing Unit (CPU) is the main processing unit within a computer. The CPU contains both the `Control Unit` (CU), which is in charge of moving and controlling data, and the `Arithmetic/Logic Unit` (ALU), which is in charge of performing various arithmetics and logical calculations as requested by a program through the assembly instructions.

The manner in which and how efficiently a CPU processes its instructions depends on its `Instruction Set Architecture` (ISA). There are multiple ISA's in the industry, each having its way of processing data. `RISC` architecture is based on processing more simple instructions, which takes more cycles, but each cycle is shorter and takes less power. The `CISC` architecture is based on fewer, more complex instructions, which can finish the requested instructions in fewer cycles, but each instruction takes more time and power to be processed.

Let us take a look at both `RISC` and `CISC`, and learn more about instructions cycles and registers.

---

## Clock Speed & Clock Cycle

Each CPU has a clock speed that indicates its overall speed. Every tick of the clock runs a clock cycle that processes a basic instruction, such as fetching an address or storing an address. Specifically, this is done by the CU or ALU.

The frequency in which the cycles occur is counted is cycles per second (`Hertz`). If a CPU has a speed of 3.0 GHz, it can run 3 billion cycles every second (per core).


![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_clock_cycle_0.jpg)

Modern processors have a multi-core design, allowing them to have multiple cycles at the same time.

---

## Instruction Cycle

An `Instruction Cycle` is the cycle it takes the CPU to process a single machine instruction.

![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_instruction_cycle.jpg)

An instruction cycle consists of four stages: `Fetch`, `Decode`, `Execute`, and `Store`:

|**Instruction**|**Description**|
|---|---|
|`1. Fetch`|Takes the next instruction's address from the `Instruction Address Register` (IAR), which tells it where the next instruction is located.|
|`2. Decode`|Takes the instruction from the IAR, and decodes it from binary to see what is required to be executed.|
|`3. Execute`|Fetch instruction operands from register/memory, and process the instruction in the `ALU` or `CU`.|
|`4. Store`|Store the new value in the destination operand.|

All of the stages in the instruction cycle are carried out by the Control Unit, except when arithmetic instructions need to be executed "**add**, **sub**, ..etc", which are executed by the **ALU**.

Each Instruction Cycle takes multiple clock cycles to finish, depending on the **CPU** architecture and the complexity of the instruction. Once a single instruction cycle ends, the **CU** increments to the next instruction and runs the same cycle on it, and so on.

![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_clock_cycle_1.jpg)

For example, if we were to execute the assembly instruction `add rax, 1`, it would run through an instruction cycle:

1. Fetch the instruction from the `rip` register, `48 83 C0 01` (in binary).
2. Decode '`48 83 C0 01`' to know it needs to perform an `add` of `1` to the value at `rax`.
3. Get the current value at `rax` (by `CU`), add `1` to it (by the `ALU`).
4. Store the new value back to `rax`.

In the past, processors used to process instructions sequentially, so they had to wait for one instruction to finish to start the next. On the other hand, modern processors can process multiple instructions in parallel by having multiple instruction/clock cycles running at the same time. This is made possible by having a multi-thread and multi-core design.

![instruction cycle](https://academy.hackthebox.com/storage/modules/85/assembly_clock_cycle_2.jpg)

## Processor Specific

As previously mentioned, each processor understands a different set of instructions. For example, while an Intel processor based on the 64-bit x86 architecture may interpret the machine code `4883C001` as `add rax, 1`, an ARM processor translates the same machine code as the `biceq r8, r0, r8, asr #6` instruction. As we can see, the same machine code performs an entirely different instruction on each processor.


This is because each processor type has a different low-level assembly language architecture known as `Instruction Set Architectures` (ISA). For example, the add instruction seen above, `add rax, 1` is for Intel x86 64-bit processors. The same instruction written for the ARM processor assembly language is represented as `add r1, r1, 1`.

`It is important to understand that each processor has its own set of instructions and corresponding machine code.`

Furthermore, a single Instruction Set Architecture may have several syntax interpretations for the same assembly code. For example, the above `add` instruction is based on the x86 architecture, which is supported by multiple processors like Intel, AMD, and legacy AT&T processors. The instruction is written as `add rax, 1` with Intel syntax, and written as `addb $0x1,%rax` with AT&T syntax.

Even though we can tell that both instructions are similar and do the same thing, their syntax is different, and the locations of the source and destinations operands are swapped as well. Still, both codes assemble the same machine code and perform the same instruction. `So, each processor type has it's Instruction Set Architectures, and each architecture can be further represented in several syntax formats`

This module will focus mainly on the Intel x86 64-bit assembly language (also known as x86_64 and AMD64), as the majority of modern computers and servers run on this processor architecture. We will be using the Intel syntax as well.

If we want to know whether our Linux system supports `x86_64` architecture, we can use the `lscpu` command:

CPU Architecture

```shell
gdxqpardo@htb[/htb]$ lscpu

Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian

<SNIP>
```

As we can see in the above output, the CPU architecture is `x86_64`, and supports 32-bit and 64-bit. The byte order is Little Endian. We can also use the `uname -m` command to get the CPU architecture. We will discuss the two most common Instruction Set Architectures in the next section: `CISC` and `RISC`.












- Stack: LIFO design.
	- Fixed in size
	- Data can only be accessed in a specific order by push-ing and pop-ing data.
- Heap: Much larger and more versatile in storing data
- Data: Hold variables and `.bss` which is usd to hold unassigned variables
- Text: Main assembly instructions are loaded into the segment to be fetch and executed by the CPU.


### Instruction Set Architectures

An `Instruction Set Architecture` (`ISA`) specifies the syntax and semantics of the assembly language on each architecture. It is not just a different syntax but is built in the core design of a processor, as it affects the way and order instructions are executed and their level of complexity. `ISA` mainly consists of the following components:

- Instructions
- Registers
- Memory Addresses
- Data Types

|Component|Description|Example|
|---|---|---|
|`Instructions`|The instruction to be processed in the `opcode operand_list` format. There are usually 1,2, or 3 comma-separated operands.|`add rax, 1`, `mov rsp, rax`, `push rax`|
|`Registers`|Used to store operands, addresses, or instructions temporarily.|`rax`, `rsp`, `rip`|
|`Memory Addresses`|The address in which data or instructions are stored. May point to memory or registers.|`0xffffffffaa8a25ff`, `0x44d0`, `$rax`|
|`Data Types`|The type of stored data.|`byte`, `word`, `double word`|


## Registers, Addresses and Data Types
###### Registers
Data registers: Usually for storing instructions/syscall arguments. 
- `rax`
- `rbx`
- `rcx`
- `rdx`
- `r8`
- `r9`
- `r10`
Pointer Registers: Used to store specific important address pointers. Main pointer registers are the base stack pointer `rbp`
- `rbp`
- `rsp`
- `rip`
Sub-Registers: Each 64-bit register can be further divided into smaller sub-registers containing the lower bits, at one byte `8-bits`, `2 bytes 16-bits`, and `4 bytes 32-bits`.

![[166336022-2d3594a5-4c3c-4612-8156-6187c81e09f6.png]]
These are the main components that distinguish different ISA's and assembly languages. We will cover each of them in more depth.

There are two main Instruction Set Architectures that are widely used:

1. `Complex Instruction Set Computer` (`CISC`) - Used in `Intel` and `AMD` processors in most computers and servers.
    
2. `Reduced Instruction Set Computer` (`RISC`) - Used in `ARM` and `Apple` processors, in most smartphones, and some modern laptops.

Let us see the pros and cons of each and the main differences between them.

---
### CISC

The `CISC` architecture was one of the earliest **ISA**'s ever developed. As its name suggests, the `CISC` architecture favors more complex instructions to be run at a time to reduce the overall number of instructions. This is done to rely as much as possible on the CPU by combining minor instructions into more complex instructions.

For example, suppose we were to add two registers with the '`add rax, rbx`' instruction. In that case, a CISC processor can do this in a single 'Fetch-Decode-Execute-Store' instruction cycle, without having to split it into multiple instructions to fetch `rax`, then fetch `rbx`, then add them, and then store them in `rax, each of which would take its own 'Fetch-Decode-Execute-Store' instruction cycle.

Two main reasons drove this:

1. To enable more instructions to be executed at once by designing the processor to run more advanced instructions in its core.
2. In the past, memory and transistors were limited, so it was preferred to write shorter programs by combining multiple instructions into one.


To enable the processors to execute complex instructions, the processor's design becomes more complicated, as it is designed to execute a vast amount of different complex instructions, each of which has its own unit to execute it.

Furthermore, even though it takes a single instruction cycle to execute a single instruction, as the instructions are more complex, each instruction cycle takes more clock cycles. This fact leads to more power consumption and heat to execute each instruction.

### RISC
The RISC architecture favors splitting intructions into minor instructions, and so the CPU is designed only to handle simple intructions. This is done to relay the optimization to the software by writing the most optimized assembly code.

For example, the same previous `add r1, r2, r3` instruction on a RISC processor would fetch `r2`, then fetch `r3`, add them, and finally store them in `r1`.

Every instruction of these takes an entire 'Fetch-Decode-Execute-Store' instruction cycle, which leads, as can be expected, to a larger number of total instructions per program, and hence a longer assembly code.

By not supporting various types of complex instructions, RISC processors only support a limited number of instructions (`~200`) compared to CISC processors (`~1500`). So, to execute complex instructions, this has to be done through a combination of minor instructions through Assembly.

It is said that we can build a general-purpose computer with a processor that only supports one instruction! This indicates that we can create very complex instructions using the `sub` instruction only. Can you think of how this may be achieved?

On the other hand, an advantage of splitting complex instructions into minor ones is having all instructions of the same length either 32-bit or 64-bit long. This enables designing the CPU clock speed around the instruction length so that executing each stage in the instruction cycle would always take precisely one machine clock cycle.

The below diagram shows how CISC instructions take a variable amount of clock cycles, while RISC instructions take a fixed amount: ![risc vs cisc cycles](https://academy.hackthebox.com/storage/modules/85/assembly_cisc_risk_cycles.jpg)

Executing each instruction stage in a single clock cycle and only executing simple instructions leads to RISC processors consuming a fraction of the power consumed by CISC processors, which makes these processors ideal for devices that run on batteries, like smartphones and laptops.

## CISC vs. RISC

The following table summarizes the main differences between CISC and RISC:

|Area|CISC|RISC|
|---|---|---|
|`Complexity`|Favors complex instructions|Favors simple instructions|
|`Length of instructions`|Longer instructions - Variable length 'multiples of 8-bits'|Shorter instructions - Fixed length '32-bit/64-bit'|
|`Total instructions per program`|Fewer total instructions - Shorter code|More total instructions - Longer code|
|`Optimization`|Relies on hardware optimization (in CPU)|Relies on software optimization (in Assembly)|
|`Instruction Execution Time`|Variable - Multiple clock cycles|Fixed - One clock cycle|
|`Instructions supported by CPU`|Many instructions (~1500)|Fewer instructions (~200)|
|`Power Consumption`|High|Very low|
|`Examples`|Intel, AMD|ARM, Apple|

In the past, having a longer assembly code due to a larger number of total instructions per program was a significant disadvantage for RISC processors due to the limited resources in memory and storage. However, today this is no longer as big of an issue, as memory and storage are not as expensive and limited as they used to be in the past.

Furthermore, with new assemblers and compilers writing extremely optimized code on the software level, RISC processors are becoming faster than CISC processors, even in executing and processing heavy applications, all while consuming much less power.

But as we speak, the overwhelming majority of computers and servers we will be pentesting are running on Intel/AMD processors with the CISC architecture, making learning CISC assembly our priority. As the basics of all Assembly language variants are pretty similar, learning ARM Assembly should be more straightforward after completing this module.



###### Glossary
- CISC: Complex Instruction Set Computer(`CISC`), Used in `Intel` + `AMD` processors in most computers and servers.
- RISC: Reduced Instruction Set Computer(`RISC`), Used in `ARM` and `Apple` processors, in most smartphones, and some modern laptops.































